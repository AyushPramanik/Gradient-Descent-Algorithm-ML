# Gradient-Descent-Algorithm-ML

Gradient Descent is an optimization algorithm used in machine learning to minimize the loss function of a model by iteratively adjusting its parameters. It works by calculating the gradient (or derivative) of the loss function with respect to the model's parameters and then updating the parameters in the opposite direction of the gradient. This process continues until the model converges to the optimal set of parameters, or reaches a local minimum of the loss function. The step size of each update is controlled by a hyperparameter called the learning rate.


File main3d.py creates 3D visual render of the of the Gradient Descent Algorithm.

File main.py creates 2D visual render of the Gradient Descent Algorithm.

Preview of 3D render produced using matplotlib shown in image below.




<p style="text-align: center"><img src="https://github.com/user-attachments/assets/e84ad1a9-1b72-4089-94e8-a0e5aa133467"></p>
